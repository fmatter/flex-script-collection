{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#language-documentation-script-collection","title":"Language documentation script collection","text":"<p>This is a collection of scripts for common language documentation workflows. Download a ZIP from or clone the repository:</p> <pre><code>git clone https://github.com/fmatter/langdoc-script-collection\n</code></pre> <p>See the documentation for individual scripts for usage instructions. It is recommended to use a virtual environment to install necessary packages.</p>"},{"location":"#contribute-a-new-script","title":"Contribute a new script","text":"<p>To add a script to the collection, fork the github repository, use a virtual environment to <code>pip install -r requirements.txt</code>, and add the following files to your fork:</p> <ol> <li>a <code>my_script.py</code> (or other suffix) file, ideally with:<ul> <li>name and contact info</li> <li>comments where necessary</li> <li>a license</li> </ul> </li> <li>a <code>docs/scripts/my_script.md</code> file with least:<ul> <li>basic setup and usage instructions</li> <li>tags (check mkdocs.yaml and add if neessary)</li> <li>requirements</li> </ul> </li> </ol> <p>Look at existing scripts and their documentation to compare  Run <code>mkdocs serve</code> and visit <code>localhost:8000</code>. Finally, create a pull request.</p>"},{"location":"#other-software","title":"Other software","text":"<ul> <li>cldflex</li> <li>flexpy</li> <li>...</li> </ul>"},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#audio","title":"audio","text":"<ul> <li>Amplify segments of speech in WAV files</li> </ul>"},{"location":"tags/#fieldworksflex","title":"FieldWorks\"&gt;flex","text":"<ul> <li>Add prefix to audio path (.lift)</li> </ul>"},{"location":"tags/#wav","title":"wav","text":"<ul> <li>Amplify segments of speech in WAV files</li> </ul>"},{"location":"scripts/amplify_wav/","title":"Amplify segments of speech in WAV files","text":"<p>Author: Wesley Kuhron Jones</p> <p>This script amplifies segments of a WAV audio file so that it is more audible when played on a laptop or speaker in the field during transcription sessions with language consultants. It has been optimized to use low amounts of RAM so that it can be run on small laptops like the Asus that I use in Papua New Guinea.</p> <p>Procedure that I follow manually:</p> <ul> <li>find a section of audio between silent spots (or at least significantly quieter than the voice volume)</li> <li>amplify it and go past clipping to some extent, so the average amplitude is enough to hear well</li> <li>ignore isolated small spikes that make the max amplitude much larger than the average, I've never had a problem with clipping too much making it hard for consultants to understand, so err on the side of being too loud</li> </ul> <p>This script automates this procedure.</p>","tags":["audio","wav"]},{"location":"scripts/amplify_wav/#setup","title":"Setup","text":"<p>Edit the variables in the area at the top of the script labeled \"PARAMS TO BE SET BY USER\".</p> <p>Requirements:</p> <pre><code>pip install numpy matplotlib\n</code></pre>","tags":["audio","wav"]},{"location":"scripts/amplify_wav/#execution","title":"Execution","text":"<pre><code>python amplify_wav.py\n</code></pre>","tags":["audio","wav"]},{"location":"scripts/amplify_wav/#source","title":"Source","text":"<pre><code># Copyright (c) 2023 Wesley Kuhron Jones &lt;wesleykuhronjones@gmail.com&gt;\n# Licensed under the MIT License, see below\n\n\n### PARAMS TO BE SET BY USER ###\n\n# set `zoom` to True if the file was created directly by the Zoom H6, False for Audacity\nzoom = True\n\n# selecting the file\nn = \"0394\"\nsuffix = \"Tr1\"\nfp = f\"Transcriptions/temp/ZOOM{n}/ZOOM{n}_{suffix}.WAV\"\n\n# what amplitude is considered \"quiet\", i.e., not containing speech\ncutting_amplitude = 0.002\n\n# make a plot of the waveform, RMS, cutting points, etc. for debugging or understanding what the script is doing\nplot = False\n\n# width of the sliding window for calculating RMS amplitude\nwindow_seconds = 1/5\n\n# amplitude to amplify the audio segments to\ntarget_amplitude = 0.25\n\n### END USER PARAMS ###\n\n\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nRATE = 44100\nMAX_AMPLITUDE = 32767\n\n\ndef get_binary_string(n, big_endian=True):\n    assert type(n) is int, type(n)\n    assert 0 &lt;= n &lt;= 255\n    if n == 0:\n        return \"0\" * 8\n    p0 = math.floor(math.log2(n))\n    y = n / (2 ** p0)\n    s = \"\"\n    while n &gt; 0:\n        x, y = divmod(y, 2)\n        s += str(int(x))\n        if y == 0:\n            break\n        y *= 2\n    assert s[0] == \"0\"\n    s = s[1:]\n    l = 1 + p0\n    s = s.ljust(l, \"0\")\n    s = s.rjust(8, \"0\")\n\n    if not big_endian:\n        s = s[::-1]\n    # print(f\"{n} -&gt; {s}\")\n    return s\n\n\ndef twos_complement(b):\n    s = \"\"\n    for c in b:\n        if c == \"0\":\n            s += \"1\"\n        elif c == \"1\":\n            s += \"0\"\n        else:\n            raise ValueError(c)\n    return s\n\n\ndef binary_to_int(b):\n    n = 0\n    for i in range(len(b)):\n        x = int(b[-(i+1)])\n        n += x * (2 ** i)\n    return n\n\n\ndef get_array_from_file(fp, zoom):\n    print(f\"opening {fp}\")\n    with open(fp, \"rb\") as f:\n        contents = f.read()\n\n    hx = contents.hex()\n    padding = 65536 if zoom else 22  # Audacity uses a different value for some reason\n\n    samples = len(hx) / 4 - padding\n    assert samples % 1 == 0, f\"samples should be an integer, got {samples}\"\n    samples = int(samples)\n\n    header_hex = hx[:4*padding]\n\n    b = bytes.fromhex(hx[4*padding:])\n    assert len(b) == 2 * samples, f\"{len(b)} != {2 * samples}\"\n\n    # for testing\n    # good_sample_range = 1014990, 1015039  # Audacity counts from 0\n\n    arr = []\n    # for i in range(*good_sample_range):\n    for i in range(samples):\n        if i % 1000000 == 0:\n            print(f\"getting array from WAV file: {i // 1000000} / {samples / 1000000:.1f} M\")\n        x, y = b[2*i : 2*i+2]\n        n = (2**8) * y + x\n        if n &gt;= 2**15:\n            # the first bit of y is 1\n            n = -1 * (2**16 - 1 - n)\n        arr.append(n)\n\n    return np.array(arr) / MAX_AMPLITUDE, header_hex\n\n\ndef get_bytes_from_int(n):\n    # clip to max amplitude\n    if n &lt; 0:\n        n = max(-MAX_AMPLITUDE, n)\n        y, x = divmod(n + 2**16 - 1, 2**8)\n    else:\n        n = min(MAX_AMPLITUDE, n)\n        y, x = divmod(n, 2**8)\n    if x &lt; 0 or x &gt; 255 or y &lt; 0 or y &gt; 255:\n        print(n, x, y)\n        raise\n    return x, y  # little-endian\n\n\ndef rms(arr):\n    return (np.mean(arr**2))**0.5\n\n\ndef sliding_rms(arr, window):\n    b = np.zeros(len(arr))\n    # pad it with zeros for the missing frames, need window-1 of them\n    n_in_front = (window - 1) // 2\n    n_in_back = (window - 1) - n_in_front\n\n    a2 = arr**2\n    for i in range(len(arr) - window + 1):\n        if i % 1000000 == 0:\n            print(f\"getting sliding rms: {i // 1000000} / {(len(arr) - window + 1) / 1000000:.1f} M\")\n        if i == 0:\n            window_sum = sum(a2[:window])\n        else:\n            window_sum -= a2[i - 1]\n            window_sum += a2[i + window - 1]\n        window_mean = window_sum / window\n        window_rms = window_mean ** 0.5\n        b[i + n_in_front] = window_rms\n    return np.array(b)\n\n\ndef get_cuttable_intervals_from_cut_arr(cut_arr):\n    interval_borders = [-0.5]\n    for i in range(len(cut_arr) - 1):\n        if i % 1000000 == 0:\n            print(f\"getting interval borders: {i // 1000000} / {len(cut_arr) / 1000000:.1f} M\")\n        a = cut_arr[i]\n        b = cut_arr[i+1]\n        if a != b:\n            interval_borders.append(i+0.5)\n    interval_borders.append(len(cut_arr) - 1 + 0.5)\n\n    cuttable_intervals = []\n    non_cuttable_intervals = []\n    # in_interval = None\n    # start_index = None\n    # last_index = None\n    for j_i in range(len(interval_borders) - 1):\n        j = interval_borders[j_i]\n        k = interval_borders[j_i + 1]\n        assert j % 1 == 0.5\n        assert k % 1 == 0.5\n        bounds = (int(j+1), int(k))\n        value = cut_arr[int(j+1)]\n        if value == 1:\n            cuttable_intervals.append(bounds)\n        elif value == 0:\n            non_cuttable_intervals.append(bounds)\n        else:\n            raise ValueError(value)\n        # the new interval starts at i = j+0.5\n\n    # for i in ?:\n        # if x == 1 and (in_interval is None or not in_interval):\n        #     # found a new interval, log its start index\n        #     interval = (start_index, last_index)\n        #     if start_index is not None:\n        #         non_cuttable_intervals.append(interval)\n        #     start_index = i\n        # if x == 0 and (in_interval is None or in_interval):\n        #     # left an interval, log the last index as the end\n        #     interval = (start_index, last_index)\n        #     if start_index is not None:\n        #         cuttable_intervals.append(interval)\n        #     start_index = i\n        # in_interval = x == 1\n        # last_index = i\n    # if we finish and we're still in an interval, log it\n    # if in_interval:\n    #     interval = (start_index, last_index)\n    #     cuttable_intervals.append(interval)\n    return cuttable_intervals, non_cuttable_intervals\n\n\ndef get_cutting_points(rms_arr, cutting_amplitude):\n    cut_arr = rms_arr &lt; cutting_amplitude\n    cuttable_intervals, sound_intervals = get_cuttable_intervals_from_cut_arr(cut_arr)\n\n    # also want average amplitude within each non-quiet interval\n    average_amplitudes = [np.mean(rms_arr[a : b+1]) for a, b in sound_intervals]\n\n    # start - 0.5 and end + 0.5 should always be cutting points, even if they're inside an interval\n    start_cut = -0.5\n    end_cut = len(rms_arr) - 1 + 0.5\n    # if we have cuttable intervals that overlap the start or end, ignore them\n    if cuttable_intervals[0][0] == 0:\n        cuttable_intervals.remove(cuttable_intervals[0])\n    if cuttable_intervals[-1][-1] == len(rms_arr) - 1:\n        cuttable_intervals.remove(cuttable_intervals[-1])\n    # for all the other ones, put the middle plus 0.5\n    cutting_points = [0.5 + int((a + b)/2) for a, b in cuttable_intervals]\n    cutting_points = [start_cut] + cutting_points + [end_cut]\n\n    return cutting_points, sound_intervals, average_amplitudes\n\n\n\nif __name__ == \"__main__\":\n    window_samples = int(RATE * window_seconds)\n    arr, header_hex = get_array_from_file(fp, zoom)\n    print(\"getting sliding rms\")\n    rms_arr = sliding_rms(arr, window_samples)\n    assert len(arr) == len(rms_arr)\n    print(\"done getting sliding rms\")\n\n    print(\"getting cutting points\")\n    cutting_points, sound_intervals, average_amplitudes = get_cutting_points(rms_arr, cutting_amplitude)\n    sound_interval_lengths = [(b - a + 1) / RATE for a, b in sound_intervals]\n    asil = sum(sound_interval_lengths) / len(sound_interval_lengths)\n    print(f\"average sound interval length: {asil:.4f} seconds\")\n    if not plot:\n        del rms_arr\n    print(\"done getting cutting points\")\n\n    # put the average in each interval at some value\n    print(\"making new_arr\")\n    new_arr = arr\n    for i in range(len(sound_intervals)):\n        cut_a, cut_b = cutting_points[i:i+2]\n        amp = average_amplitudes[i]\n        r = target_amplitude / amp\n        new_arr[int(cut_a + 1) : int(cut_b + 1)] *= r\n    new_arr_int = (new_arr * 2**15).astype(int)\n    if not plot:\n        del new_arr\n        del arr\n    print(\"done making new_arr\")\n\n    if plot:\n        print(\"making plots\")\n        plt.subplot(3,1,1)\n        plt.plot(arr)\n\n        plt.subplot(3,1,2)\n        plt.plot(rms_arr)\n        for x in cutting_points:\n            plt.plot([x, x], [0, max(rms_arr)], c=\"r\")\n        for i in range(len(sound_intervals)):\n            a, b = sound_intervals[i]\n            y = average_amplitudes[i]\n            plt.plot([a, b], [y, y], c=\"k\")\n\n        plt.subplot(3,1,3)\n        plt.plot(new_arr)\n        for y in [1, -1]:\n            plt.plot([0, len(rms_arr) - 1], [y, y], c=\"k\")\n\n        plt.gcf().set_size_inches((12, 6))\n        plt.savefig(\"a.png\")\n\n        del arr\n        del new_arr\n        del rms_arr\n\n    print(\"making bytes\")\n    b = np.zeros(2 * len(new_arr_int), dtype=int)\n    for i, n in enumerate(new_arr_int):\n        if i % 1000000 == 0:\n            print(f\"making bytes: {i // 1000000} / {len(new_arr_int) / 1000000:.1f} M\")\n        x, y = get_bytes_from_int(n)\n        b[2*i] = x\n        b[2*i + 1] = y\n        # print(n, x, y, b[max(0, 2*i - 4) : min(2*len(new_arr_int), 2*i + 5)])\n    # b = []\n    # for n in new_arr_int:\n    #     b += list(get_bytes_from_int(n))\n    # b = np.array(\n\n    assert b.min() &gt;= 0 and b.max() &lt;= 255\n    b = bytes.fromhex(header_hex) + bytes(x for x in b)  # don't cast np array to bytes, it messes the result up somehow\n    print(\"done making bytes\")\n    output_fp = fp.replace(\".\", \"_Amplified.\")\n    print(f\"writing to {output_fp}\")\n    with open(output_fp, \"wb\") as f:\n        f.write(b)\n\n\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n</code></pre>","tags":["audio","wav"]},{"location":"scripts/dict_audio_path/","title":"Add prefix to audio path (<code>.lift</code>)","text":"<p>This script iterates a <code>.lift</code> export and modifies the <code>href</code> attribute of every <code>media</code> tag. This is where paths to audio files are stored.</p>","tags":["flex"]},{"location":"scripts/dict_audio_path/#setup","title":"Setup","text":"<p>The modification consists of adding a prefix to the path. Edit the variables <code>PREFIX</code> and <code>TARGET</code> in the script. It is very easy to implement other modifications using this as a basis (modifying attributes of entities).</p> <p>Requirements:</p> <pre><code>pip install beautifulsoup4\n</code></pre>","tags":["flex"]},{"location":"scripts/dict_audio_path/#execution","title":"Execution","text":"<pre><code>python fix_audio_path.py\n\nChanging file-1.wav to:\n/home/audio/file-1.wav\n...\n</code></pre>","tags":["flex"]},{"location":"scripts/dict_audio_path/#source","title":"Source","text":"<pre><code># Copyright (c) 2023 Florian Matter &lt;flmt@mailbox.org&gt;\n# Licensed under the MIT License, see below\n\n# The file you want to modify.\nTARGET = \"path/to/my_lexicon.lift\"\n# The string to be added to a path.\nPREFIX = \"/path/to/my/audio/\"\n\nfrom bs4 import BeautifulSoup\nwith open(TARGET) as fp:\n    soup = BeautifulSoup(fp, \"xml\")\nfor media in soup.find_all(\"media\"):\n    if \"href\" in media.attrs:\n        old = media[\"href\"]\n        if PREFIX not in old:\n            new = PREFIX + old\n            print(f\"Changing {old} to:\\n{new}\")\n            media[\"href\"] = new\nwith open(TARGET, \"w\") as f:\n    f.write(str(soup))\n\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n</code></pre>","tags":["flex"]},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#audio","title":"audio","text":"<ul> <li>Amplify segments of speech in WAV files</li> </ul>"},{"location":"tags/#fieldworksflex","title":"FieldWorks\"&gt;flex","text":"<ul> <li>Add prefix to audio path (.lift)</li> </ul>"},{"location":"tags/#wav","title":"wav","text":"<ul> <li>Amplify segments of speech in WAV files</li> </ul>"}]}